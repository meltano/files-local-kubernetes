# Example Meltano Project Deployed to a Local Kubernetes Cluster

**Warning:** Here be dragons. This is an attempt to arrive at a minimal config required to launch Meltano on k8s, for design, planning and documentation purposes. It is not yet intended for production use.

## Install

This repos can be installed into your project as a custom [File Bundle](https://meltano.com/docs/plugins.html#file-bundles), using the pip url `git+https://gitlab.com/meltano/infra/files-local-kubernetes.git` when prompted:

```bash
meltano add --custom files local-kubernetes
```

## Setup

Before getting started with the deployment, a few tools are needed. These are all cross-platform (MacOS and Windows at least) ad are installable via `brew` or `chocolatey` respectively:

- Docker Desktop for running containers locally
- Kind for deploying Kubernetes into containers
- Terraform for manading the deployment and configuration of Kind
- `kubectl` for interacting with Kubernetes
- `helm` for deploying apps onto Kubernetes
- Lens for exploring the deployment in a lovely UI

If you have deployed applications before, you may already have many of these tools.

## Deployment ðŸš€

1. Configure Your Meltano Project

For Airflow to run on Kubernetes with a Postgres backend database, add both `psycopg2` and the `kubernetes` option to your Airflow pip URL:

```yaml
orchestrators:
- name: airflow
    pip_url: psycopg2 apache-airflow[kubernetes]==2.1.2 --constraint https://raw.githubusercontent.com/apache/airflow/constraints-2.1.2/constraints-${MELTANO__PYTHON_VERSION}.txt
```

There are also some Airflow config required (in future this will be moved to ENV vars directly in Terraform):

```yaml
orchestrators:
- name: airflow
pip_url: psycopg2 apache-airflow[kubernetes]==2.1.2 --constraint https://raw.githubusercontent.com/apache/airflow/constraints-2.1.2/constraints-${MELTANO__PYTHON_VERSION}.txt
config:
  webserver:
    rbac: false
    expose_config: true
    authenticate: false
    base_url: /airflow
  core:
    executor: KubernetesExecutor
  kubernetes:
    delete_worker_pods: false
    namespace: meltano
    worker_container_repository: registry:5000/meltano
    worker_container_tag: latest
    in_cluster: true
    pod_template_file: /project/.meltano/run/airflow/pod-template-file.yml
```

1. Deploy Meltano

With the above in place, deployment is as simple as:

```bash
# change to the local deployment dir
cd deploy/local
# Initialise Terraform. This installs the required providers.
terraform init
# See what terraform will create
terraform plan
# Apply to deploy
terraform apply
```

## What is actually deployed?

Quite a lot...

- A local docker registry, to push and pull images to and from.
- Promethius for logging of container and kubernetes cluster metrics.
- A Postgres database instance, configured with two databases for Meltano and Airflow.
- An NFS file server provisioner, for logs and output data.
- Nginx ingress controller, to expose Meltano at [localhost](http://localhost) and Airflow at [localhost/airflow](http://localhost/airflow).
- The Meltano UI.
- Airflow.
  - Airflow is deployed in two containers, for the webserver and scheduler.
  - It is configured to use the Kubernetes Executor, which dynamically provisions a pod per task.
  - Logging is centralised using a shared NFS volume mount.

## How do I see what it is doing?

- Check out the respective UI's; Meltano at [localhost](http://localhost) and Airflow at [localhost/airflow](http://localhost/airflow).
- For seeing the containers created, and for connecting directly to them, I recommend using Lens to explore.
  - Meltano and Airflow are deployed into a namespace called `meltano`. Each container can be connected to directly.
- Airflow logs are centralised using a shared NFS volume mounted at `/project/.meltano/run/airflow/logs`. This can be used to access log files directly. Logs are viewable for each task in the Airflow UI too as normal.

## What do I do if something goes wrong?

As kubernetes is just running in docker locally, the ultimate recourse to fixing things is to drop the cluster and start again:

```bash
kind delete cluster --name="meltano-cluster"
```

At that point you will also want to delete the state files generated by terraform too, as they relate to the resources we just deleted. You'll be prompted to run `terraform init` again as we removed the `.terraform` folder for good measure:

```bash
.terraform
.terraform.lock.hcl
terraform.tfstate
terraform.tfstate.backup
meltano-cluster-config
```

Finally, delete the local registry container in Docker Desktop to avoid name-clashes if/when you redeploy.
